
\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}

\title{Optimisation}
\author{Keith Goh}
\begin{document}
\maketitle

\section{Whats reviewed}
Lecture 1 ,2 and 3
tutorial 1,2,3 ,4, 5 ,6,7,8
\section{Lecture 1\_1}
Notes:
Linear function all components are linear(only x)\\
unbounded if a solution approaches infinity for maxi problem and negative infinity for minimization problem\\
linear programme->constraints and obj function linear
\section{Tutorial 1}
How a simple algebraic formulation might look like
$$
\begin{array} { l } { \cdot \text { Let } x _ { 1 } \text { be the number of ads purchased of type j for } j = 1 \text { to } n . } \\ { \text { Let } a _ { j } \text { be the number of persons who view one ad of type i } } \\ { \text { total number of viewers must be at least b) } } \\ { \text { Let } d _ { 1 } \text { be an uper bound on the number of ads purchased of type j. } } \\ { \text { Minimize } \sum _ { j = 1 } ^ { n } C _ { i } x _ { i } } \\ { \text { subject to } \sum _ { j = 1 } ^ { n } a _ { i } x _ { i } \geq b } \\ { 0 \leq x _ { j } \leq d _ { j } \text { for } j = 1 \text { to } n . } \end{array}
$$
How a normal list of constraints might look like:
$$
\begin{array} { l } { a _ { 11 } x _ { 1 } + a _ { 12 } x _ { 2 } \leq b _ { 1 } } \\ { a _ { 21 } x _ { 1 } + a _ { 22 } x _ { 2 } \leq b _ { 2 } } \\ { a _ { 31 } x _ { 1 } + a _ { 32 } x _ { 2 } \leq b _ { 3 } } \end{array}
$$
How it looks like in algebraic
$$
\begin{array} { l } { \sum _ { j = 1 } ^ { n } a _ { i j } x _ { j } \leq b _ { i } } \\ { \text { for } i = 1 \text { to } m . } \end{array}
$$
n  :	the number of items.\\
$a_{ij}$: the amount of resource i used up by one unit of item j.\\
m : 	the number of different resources.\\

Standard form of Lp:
$$
\begin{array} { l l l } { \text { maximize } } & { z = \sum _ { j - 1 } ^ { n } c _ { j } x _ { j } } \\ { \text { subject to } } & { \quad \sum _ { j = 1 } ^ { n } a _ { i j } x _ { j } = b _ { i } } & { \text { for } i = 1 \text { to } m } \\ { } & { x _ { j } \geq 0 } & { \text { for } j = 1 \text { to } n } \end{array}
$$
\section {Lecture 1\_2}
$$
\begin{array} { l } { \text { Least squares: } } \\ {\left. \qquad \begin{array} { r l } { \min } & { \sum _ { i = 1 } ^ { 6 } \left( P _ { i } - b _ { 0 } - b _ { 1 } L _ { i } - b _ { 2 } E _ { i } \right) ^ { 2 } } \\ { } & { b _ { 0 } , b _ { 1 } , b _ { 2 } \in \mathbb { R } } \end{array} \right\} } \end{array}
$$

$$
\left.\begin{array} { c c c c  c} { \text {Linear Absolute Regression} } & { \min } & { \sum _ { i = 1 } ^ { 6 } \left( r _ { i } ^ { + } + r _ { i } ^ { - } \right) } & { } & { } \\ { \forall i = 1 , \ldots , 6 } & { r _ { i } ^ { + } - r _ { i } ^ { - } + b _ { 0 } + b _ { 1 } L _ { i } + b _ { 2 } E _ { i } } & { = } & { P _ { i } } \\ { r i = 1 , \ldots , 6 } & { r _ { i } ^ { + } , r _ { i } ^ { - } } & { \geqslant 0 } \\ { b _ { 0 } , b _ { 1 } , b _ { 2 } } & { \in \mathbb { R } } \end{array} \right\}
$$
$$
\begin{array} { l } { \text { Maximum absolute residuals: } } \\ {\left. \qquad \begin{array} { r l  c} { } & { \min } &{r}\\ { \forall i = 1 , \ldots , 6 } & { P _ { i } - b _ { 0 } L _ { i } - b _ { 2 } E _ { i } } & { \leqslant r } \\ { \forall i = 1 , \ldots , 6 } & { b _ { 0 } + b _ { 1 } L _ { i } + b _ { 2 } E _ { i } - P _ { i } } & { \leqslant r } \\ { r , b _ { 0 } , b _ { 1 } , b _ { 2 } } & { \in \mathbb { R } } \end{array} \right\} } \end{array}
$$

Converting to standard form\\
For free variables split into 2 variables plus variable 1 for the postive variable and minus negative variable 2\\
To convert from $\geq$ or $\leq$ to equal we add surplus/slack variables\\
- the variable if it is $\geq$\\
+ the variable if it is $\leq$\\
making sure all variables are $\geq$ 0 by introducing negative to flip the sign if neccesary\\
RHS variables must be positive\\
adding artificial variables(more for to make into canonical)\\

\begin{enumerate}
  \item $A x^*$ = b, and
  \item there exists indices $B_1$, $B_2$,...$B_m$ such that:
  \begin{enumerate}
    \item  The m columns of matrix A, $A_{B1}$,$A_{B2}$,..., and $A_{B_m}$, are linearly independent;
    \item  The decision variables not associated with the m linearly independent columns are zero, i.e., $x_i^*$ = 0 for i $\neq$ $B_1$,$B_2$,...$B_m$
  \end {enumerate}
\end{enumerate}
The set of variables {$x_{B1},x_{B2},..,x_{Bm}$} is called a
basis. The variables $x_{B1},x_{B2},..,x_{Bm}$ are called basic variables. The variables $x_i$ for i $\neq$ $B_1$,$B_2$,...$B_m$ are called nonbasic variables.
$$
\begin{array} { l } { \text { Consider an LP in the standard from } } \\ {\left. \qquad \begin{array} { c } { \max  } { \text{ }} c ^ { T }{ x } \\ { \text { s.t.: } A x = b } \\ { x \geq 0 } \end{array} \right\} } \end{array}
$$
where A is an m $\times$ n matrix with linearly independent rows and b  $\in \mathbb { R } ^ { m}_{+} $ A vector $x^*$ is a basic solution if

$$
\begin{array} { l } { \text { An LP is in canonical form if: } } \\ { \text { "It is in standard form (with possibly a constant term in the } } \\ { \text { objective function). } } \\ { \text { Objective function, contains (a permutation of) the } } \\ { \text { identity matrix as a submatrix. } } \\ { \text { The variables with a "+1" coefficient in the identity matrix } } \\ { \text { appear with a zero coefficient in the objective function. } } \end{array}
$$
Hence we just add a row of artificial variables to make an identity matrix at the right.\\
Notes:\\
Lp standard form for this course is max\\
m x n matrix got n constraints and n linearly independent rows\\
linearly independ rows(basis)\\
x for non linearly independent row=0(non basic variable)\\
\section{Tutorial 2}
$$
|{x_1 + x_2 - x_3 - x_4}|\leq 5
$$
can be changed to
$$
x_1 + x_2 - x_3 - x_4 \leq 5
$$
and
$$
-x_1 - x_2 + x_3 + x_4 \leq 5
$$
Original equation:
$$
\begin{array} { l } { \text { Minimize 500$x_1$+200$x_2$+250$x_3$+125$x_4$} } \\ { \begin{array} { r l } { \text { subject to } } & { 50 \mathrm { x } _ { 1 } + 25 \mathrm { x } _ { 2 } + 20 \mathrm { x } _ { 3 } + 15 \mathrm { x } _ { 4 } \geq 1,500 } \\ { 0 \leq \mathrm { x } _ { 1 } \leq 20 } & { 0 \leq \mathrm { x } _ { 2 } \leq 15 \quad 0 \leq \mathrm { x } _ { 3 } \leq 25 \quad 0 \leq \mathrm { x } _ { 4 } \leq 15 } \end{array} } \end{array}
$$
if we want to maximize the minimum of each constraint:
we make the new variable z $\leq$ each of the components of the constraint and maximum that variable

$$
\begin{array} { l } { \text { maximize } z } \\ { \text { subject to } \quad 50 \mathrm { x } _ { 1 } + 25 \mathrm { x } _ { 2 } + 20 \mathrm { x } _ { 3 } + 15 \mathrm { x } _ { 4 } \geq 1,500 } \\ { \quad 0 \leq \mathrm { x } _ { 1 } \leq 20 \quad 0 \leq \mathrm { x } _ { 2 } \leq 15 \quad 0 \leq \mathrm { x } _ { 3 } \leq 25 \quad 0 \leq \mathrm { x } _ { 4 } \leq 15 } \\ { \quad \mathrm { z } \leq 50 \mathrm { x } _ { 1 } , \quad \mathrm { z } \leq 25 \mathrm { x } _ { 2 } , \quad \mathrm { z } \leq 20 \mathrm { x } _ { 3 } , \quad \mathrm { z } \leq 15 \mathrm { x } _ { 4 } } \end{array}
$$
If we want to minimize the maximum, we make the new variable $\geq$ to each of the original obj functions and minimize that variable
$$
\begin{array} { l l } { \text { Minimize } } & { \text { Z } } \\ { \text { subject to } } & {< \text { linear constraints } > } \\ { } & { x \geq 0 , y \geq 0 } \\ { } & { z \geq 3 x + 1 } \\ { } & { z \geq 4 y - 2 } \end{array}
$$
If we want to make a constraint where one variable must be a certain percentage of the whole amount produced: We can use this trick
$$
\begin{array} { l } { x _ { 1 } / \left( x _ { 1 } + x _ { 2 } + x _ { 3 } + x _ { 4 } \right) \geq 0.2 } \\ { x _ { 1 } \geq 0.2 \left( x _ { 1 } + x _ { 2 } + x _ { 3 } + x _ { 4 } \right) } \\ { \text { Equivalently, } } \\ { 0.8 x _ { 1 } - 0.2 x _ { 2 } - 0.2 x _ { 3 } - 0.2 x _ { 4 } \geq 0 } \end{array}
$$
But we need to make sure all variables in denominator are positive or 0,also make sure denominator does not add up to 0.\\

\section {Tutorial 3}
Basically a recap of conversion to standard form.\\
\begin{enumerate}
\item Standard Form must have non negativity constraints on all variables
\item All remaining constraints are equality constraints
\item RHS vector is non negative
\end{enumerate}
Tips to convert
\begin{enumerate}
\item For non positive constraint on the RHS flip row of constraint(note:must be done before adding slack/surplus variable)
\item For $\leq$ add +s
\item For $\geq$ add -s
\item For non positive variables flip all variables
\item For free variables we can use 2 variables to sub that variable one +y1 -y2 (easy way)
\item Or use one constraint by making the variable the subject of the constraint to sub into all other constraints and obj function
\item to convert maximize to minimize and vice versa add negative sign on both sides
\end{enumerate}
\section{Tutorial 4}
\begin{enumerate}
  \item ERO 1:  Multiply a row by a constant
  \item ERO 2:  Add a multiple of one row to another
  \item ERO 3:  Interchange two rows.
\end{enumerate}
Try to perform gaussian elimination till you get an identity matrix or are unable to continue
To pivot on entry (i, j) of a matrix is to carry out EROs so that
\begin{enumerate}
  \item Row i is multiplied by a constant
  \item Every other row has a multiple of Row i added to it.
  \item After the operations, Column j has a 1 in Row i and a 0 elsewhere.
\end{enumerate}

\section{Tutorial 5}
$$
\begin{array}{ll}{\text { maximize }} & {z=c x} \\ {\text { subject to }} & {A x=b} \\ {} & {x \geq 0}\end{array}
$$
This linear Program can be rewritten as \\

$$
\begin{array} { l l l } { \max } & { \sum _ { j = 1 } ^ { n } c _ { j } x _ { j } } \\ { \text { s.t } } & { \sum _ { j = 1 } ^ { n } a _ { i j } x _ { j } = b _ { i } } & { \forall i = 1 \text { to } m } \\ { } & { \quad x _ { j } \geq 0 } & { \forall j = 1 \text { to } n } \end{array}
$$
$$
\begin{array} { | c | c | c | c | c | c | c | c | } \hline - z & { x _ { 1 } } & { x _ { 2 } } & { x _ { 3 } } & { x _ { 4 } } & { x _ { 5 } } & &{ \quad \text { RHS } } \\ \hline 1 & { c _ { 1 } } & { c _ { 2 } } & { c _ { 3 } } & { c _ { 4 } } & { c _ { 5 } } & { = } & { - z _ { 0 } } \\ \hline { 0 } & { a _ { 11 } } & { a _ { 12 } } & { a _ { 13 } } & { a _ { 14 } } & { a _ { 15 } } & { = } & { b _ { 1 } } \\ \hline 0 & { a _ { 21 } } & { a _ { 22 } } & { a _ { 23 } } & { a _ { 24 } } & { a _ { 25 } } & { = } & { b _ { 2 } } \\ \hline 0 & { a _ { 31 } } & { a _ { 32 } } & { a _ { 33 } } & { a _ { 34 } } & { a _ { 35 } } & { = } & { b _ { 3 } } \\ \hline \end{array}
$$
We put a bar over the symbols to indicate that it may not be the original tableau
$$
\begin{array} { | c | c | c | c | c | c | c | c |} \hline - 2 & { x _ { 1 } } & { x _ { 2 } } & { x _ { 3 } } & { x _ { 4 } } & { x _ { 5 } } & { } & { \text { RHS } } \\ \hline 1 & { \overline { c } _ { 1 } } & { \overline { c } _ { 2 } } & { \overline { c } _ { 3 } } & { \overline { c } _ { 4 } } & { \overline { c } _ { 5 } } & { = } & {  - \overline {z} _ { 0 } }   \\ \hline { 0 } & { \overline { a } _ { 11 } } & { \overline { a } _ { 12 } } & { \overline { a } _ { 13 } } & { \overline { a } _ { 14 } } & { \overline { a } _ { 15 } } & { = } & { \overline { b } _ { 1 } } \\ \hline 0 & { \overline { a } _ { 21 } } & { \overline { a } _ { 22 } } & { \overline { a } _ { 23 } } & { \overline { a } _ { 24 } } & { \overline { a } _ { 25 } } & { = } & { \overline { b } _ { 2 } } \\ \hline 0 & { \overline { a } _ { 31 } } & { \overline { a } _ { 32 } } & { \overline { a } _ { 33 } } & { \overline { a } _ { 34 } } & { \overline { a } _ { 35 } } & { = } & { \overline { b } _ { 3 } } \\ \hline \end{array}
$$

We even have notation for the entering and leaving variables.  The entering variable is typically denoted as variable $x_s$.  For it to be an entering variable we need $\overline{c_s} >$ 0.


Then we carry out the min ratio test to find the row on which to pivot.  This row is typically given the index of r.
$$
\begin{array} { | c | c | c | c | c | c | c | c | } \hline - 2 & { x _ { 1 } } & { x _ { 2 } } & { x _ { 3 } } & { x _ { 4 } } & { x _ { 5 } } & { } & { \text { RHS } } \\ \hline 1 & { \overline { c } _ { 1 } } & { \overline { c } _ { 2 } } & { \overline { c } _ { 3 } } & { \overline { c } _ { 4 } } & { \overline { c } _ { 5 } } & { = } & { - \overline { z } _ { 0 } } \\ \hline { 0 } & { \overline { a } _ { 11 } } & { \overline { a } _ { 12 } } & { \overline { a } _ { 13 } } & { \overline { a } _ { 14 } } & { \overline { a } _ { 1 s } } & { = } & { \overline { b } _ { 1 } } \\ \hline 0 & {{\overline{ a} _ { r1 } } } & { \overline { a } _ { r2 } } & { \overline { a } _ { r3 } } & { \overline { a } _ { r4 } } & { \overline { a } _ { r s } } & {=}&{   { \overline { b } _ { r } }  } \\ \hline { 0 } & { \overline { a } _ { 31 } } & { \overline { a } _ { 32 } } & { \overline { a } _ { 33 } } & { \overline { a } _ { 34 } } & { \overline { a } _ { 33 } } & { = } & { \overline { b } _ { 3 } } \\ \hline \end{array}
$$
\section{lecture $2\_1$}
Given an LP in a canonical form associated with a basis, the\\
coefficient with which a variable appears in the objective\\
function is called the reduced cost of that variable associated\\
with that basis.\\

Simplex Algo:
\begin{enumerate}
  \item Choose a positive reduced cost variable(Usually biggest one if we are greedy but may cycle)
  \item Do ratio test ($\frac{\text{RHS coefficient}}{\text{Coefficient in constraint variable}} $) to find minimum this will be pivot
  \item using this row convert the other rows to ensure that the coefficient of the(entering) variable in the rest of the row is 0, remember to change the entering basis variable coefficient to 1
  \item Do this until all reduced cost are non positive(optimal) or until all the coefficient of a positive reduced cost is negative(unbounded)
\end{enumerate}
At the end of phase 1,
\begin{enumerate}
  \item if objective function is non zero then no feasible solution.\\
  \item if obj function is zero\\
    \begin{enumerate}
      \item no artificial variable in basis: we have BFS, drop artificial variable for BFS
      \item Some artificial variable in basis, pivot out , if cannot there are redundant constraints we can drop, then drop artificial variables and obtain BFS
    \end{enumerate}
\end{enumerate}
This BFS forms the BFS for phase 2. change your objective function back to original and solve it using simplex algorithm again.
We will get the answer as the obj function RHS and can read the value of variable from the RHS of the basis after we have finished the simplex algorithm.\\
Notes:\\
We increase objective function by increasing value of one of the non basic variable(we increase from 0 to some maximum value that another variable become 0 to replace it as the non basic variable),this causes the obj function to also increase as we like squeezing out some value out of the non basic variable and subbing another basic variable to sub it.\\
They are all related to each other by a ratio, so when one variable, the non basic variable increase, some other variables, the basic variable will become smaller, we do this till one of the non basic variable become 0(not only those that are positive will become smaller, hence that's why we need at least one positive coefficient in a tableau to be like the limit, and if all variables are negative, we can increase to infinity thus unbounded), then we sub out that point for the rest of pts.\\
Intuition(at first is like got a value times x=0 cus they non basic variable hence like obj function is 0)\\
Later we move around such that is negative coeff for non basic variable and basic variable and positive coeff(at rhs) for basic coeff hence obj function maximized.\\
Simplex algorithm is in essence just moving around the corners of a region.\\
Intuition why we do till all negative reduced cost for no basic variable because they times x=0 then 0 so don't decrease objective function.\\
\section{Tutorial 6}
A basic feasible solution is called degenerate if one of its RHS coefficients (excluding the objective value) is 0.\\
When a corner point is the solution of two different sets of equality constraints, then this is called degeneracy.  This will turn out to be important for the simplex algorithm.\\
We say that a basis is degenerate if a basic variable is 0. (easiest definition)\\
Blandâ€™s Rule.(to ensure no cycling)
\begin{enumerate}
  \item The entering variable should be the lowest index variable with negative reduced cost.
  \item The leaving variable (in case of a tie in the min ratio test) should be the variable with the lowest index.

\end{enumerate}
Finally, degeneracy is similar to but different from the condition for alternate optima.  In degeneracy, one of the RHS values is 0.  For alternate optima, in an optimal tableau one of the non-basic cost coefficients is 0.

\section{Lecture $2\_2$}
Eliminate artificial variables to get initial BFS\\
A simple tableau such that at least one of the right-hand side\\
values is zero is called degenerate, and the corresponding BFS\\
is degenerate.\\
Possible to change basis but BFS stays the same, pivot does not move point and may cause cycling\\
Bland Rule\\
\begin{enumerate}
  \item  Among variables with positive reduced cost, choose the one with the smallest index as the entering variable.
  \item If there is a tie in the min ratio test, choose the one with the smallest index as the leaving variable.
\end{enumerate}
$$
\left.\begin{array} { r l } { \max } & { c _ { B } x _ { B } + c _ { N } x _ { N } } \\ { A _ { B } x _ { B } + A _ { N } x _ { N } } & { = b } \\ { x _ { B } , x _ { N } } & { \geqslant 0 } \end{array} \right\}
$$
where c, $c_b$ and $c_N$ are row vectors\\
$c_B$ refers to cost of basic variables\\
$c_N$ refers to cost of non-basic variables\\
$A_B$ is the basis matrix\\

We perform elementary row operations to obtain the
RREF of the augmented matrix for the equality constraints.
Equivalently, multiply $A_B^{-1}$ on both sides of the equation.

$$
\left.\begin{array} { r l } { \max } & { c _ { B } x _ { B } + c _ { N } x _ { N } } \\ { } & { I x _ { B } + A _ { B } ^ { - 1 } A _ { N } x _ { N } = A _ { B } ^ { - 1 } b } \\ { x _ { B } , x _ { N } } & { \geqslant 0 } \end{array} \right\}
$$
Finally, eliminate the basic variables in the objective function
using $x _ { B } = A _ { B } ^ { - 1 } b - A _ { B } ^ { - 1 } A _ { N } x _ { N }$
$$
\left.\begin{array} { r l } { \max \left( c _ { N } - c _ { B } A _ { B } ^ { - 1 } A _ { N } \right) x _ { N } + c _ { B } A _ { B } ^ { - 1 } b } & { } \\ { I x _ { B } + A _ { B } ^ { - 1 } A _ { N } x _ { N } } & { = A _ { B } ^ { - 1 } b } \\ { x _ { B } , x _ { N } } & { \geqslant 0 } \end{array} \right\}
$$
$$
\begin{array} { | c | c | c | c | c| } \hline \text { Basic } & { x _ { B } } & { x _ { N } }&& \\ \hline ( - z ) & { 0 } & { c _ { N } - c _ { B } A _ { B } ^ { - 1 } A _ { N } } & { =}&{ - c _ { B } A _ { B } ^ { - 1 } b } \\ \hline x _ { B } & { I } & { A _ { B } ^ { - 1 } A _ { N } } & { = } & { A _ { B } ^ { - 1 } b } \\ \hline \end{array}
  $$

  $$
\begin{array} { l } { \text { With respect to a basis with matrix } A _ { B } , \text { we define: } } \\ { \cdot \text { The simplex multipliers: } y _ { B } = c _ { B } A _ { B } ^ { - 1 } } \\ { \cdot \text { The reduced costs of } x _ { N } : \overline { c } _ { N } = c _ { N } - c _ { B } A _ { B } ^ { - 1 } A _ { N } = c _ { N } - y _ { B } A _ { N } } \\ { \text { . The reduced costs of } x _ { B } : \overline { c } _ { B } = 0 } \\ { \text { . The objective function value } \overline { z } = c _ { B } A _ { B } ^ { - 1 } b = y _ { B } b } \\ { \cdot \overline { A } _ { N } = A _ { B } ^ { - 1 } A _ { N } } \\ { \text { . The values of the basic variables: } \overline { b } = A _ { B } ^ { - 1 } b } \end{array}
$$

Hence the tableau above can be defined as
$$
\begin{array} { | c | c | c | c | c | } \hline \text { Basic } & { x _ { B } } & { x _ { N } } & { }& \\ \hline ( - z ) & { 0 } & { \overline { C } _ { N } } & { = }&{ - \overline { z } } \\ \hline x _ { B } & { I } & { \overline { A } _ { N } } & { = }&{ \overline { b } } \\ \hline \end{array}
  $$

  $$
\left.\begin{array} { r c c c c c  c c c c c c } { \max } & { 5 x _ { 1 } } & { + 2 x _ { 2 } } & { + 3 x _ { 3 } } & { - 4 x _ { 4 } } & { + 2 x _ { 5 } }&&& \\ { } & &{ x _ { 2 } } & { } & { - x _ { 4 } } & { - x _ { 5 } } & { + x _ { 6 } } &&& { = } & { 11 } \\ &{ x _ { 1 } } & { } & { } & { } & { + x _ { 5 } } && { + x _ { 7 } } & { } & { =}&{ 9 } \\ &{ - x _ { 1 } } & { - x _ { 2 } } & { + x _ { 3 } } & { + x _ { 4 } } & { } & { } && { x _ { 8 } } & { =}&{ 4 } \\& { x _ { 1 } , } & { x _ { 2 } , } & { x _ { 3 } , } & { x _ { 4 } , } & { x _ { 5 } , } & { x _ { 6 } , } & { x _ { 7 } , } & { x _ { 8 } } & { \geqslant}&{ 0 } \end{array} \right\}
$$

$c_B$= [2 5 3] $C_N$= [-4 2 0 0 0 ]
$$
\begin{array} { | c | c | c | c | c | c | c | c | c | c |} \hline \text { Basic } & { x _ { 1 } } & { x _ { 2 } } & { x _ { 3 } } & { x _ { 4 } } & { x _ { 5 } } & { x _ { 6 } } & { x _ { 7 } } & { x _ { 8 } } & { \text { Rhs } } \\ \hline ( - z ) & { 0 } & { 0 } & { 0 } & { - 2 } & { - 1 } & { - 5 } & { - 8 } & { - 3 } & { - 139 } \\ \hline x _ { 2 } & { } & { 1 } & { } & { - 1 } & { -1 } & {1 } & &&{ 11 } \\ { x _ { 1 } } & { 1 } & { } & { } && { 1 } & { } & { 1 } & {  } & { 9 } \\ { x_3}&&&{1}&&&{1}&{1}&{1}&{24}\\ \hline \end{array}
$$

$$
\begin{array} { l } { \text { Consider an } L P \text { of the form max } \{ c x | A x \leqslant b , x \geqslant 0 \} , \text { where } b \geqslant 0 } \\ { \text { and its canonical form max } \{ c x | A x + I s = b , x \geqslant 0 , s \geq 0 \} , \text { where s } } \\ { \text { is the vector of slack variables. } } \\ { \text { With respect to a basis } B \text { , the reduced cost of a slack variable is } } \\ { \text { the negative of the simplex multiplier for the corresponding } } \\ { \text { constraint. The column in the tableau corresponding to the } } \\ { \text { slack variable } s _ { j } , \overline { A } _ { s j } \text { is the } j ^ { t h } \text { column of } A _ { B } ^ { - 1 } \text { . } } \end{array}
$$
This is just saying that the simplex multiplier $y_B$ is the negative of the reduced cost of the slack variables, i.e. variables (that coincidentally form a diagonal at the end.(to make equation slack)\\
In this case is the [5 8 3]\\
$$
\begin{array} { l } { \text { The revised simplex method in three steps: } } \\ { \text { 1. Find a nonbasic variable } s \text { such that } \overline { c } _ { s } = c _ { s } - y _ { B } A _ { s } > 0 } \\ { \text { If none exists stop: the tableau is optimal. } } \\ { \text { 2. Compute } \overline { A } _ { s } = A _ { B } ^ { - 1 } A _ { s } \text { . Find } } \\ { \qquad r = \arg \min _ { i = 1 , \ldots , m } \left\{ \frac { \overline { b } _ { i } } { \overline { a } _ { i s } } : \overline { a } _ { i s } > 0 \right\} } \\ { \text { if all } \overline { a } _ { i s } \leqslant 0 \text { stop: the problem is unbounded. } } \\ { \text { 3. } x _ { s } \text { enters the basis, } x _ { r } \text { leaves. Update: } x _ { B } , A _ { B } ^ { - 1 } , y _ { B } , \overline { b } \text { . } } \end{array}
$$
1. can be interpreted as finding a cost after a pivot that is positive\\
2. can be interpreted as finding using the min ratio test to find an argument which is positive and minimum\\
Notes:\\
$A_N$ refers to array of (N)on basic variables constraints coeff.
so the big N refers to non basic variables,small B refers to basic variables
\section{Lecture 3\_1}
Do rmb those with a bar on top is the changed result after undergoing pivoting(for this lecture it refers to usually the final tableau cost),those without is the initial.
$$
\begin{array} { l r } { \text { All questions asked a few slides back can be answered using } } \\ { \text { the following formulas, that are fundamental for sensitivity } } \\ { \text { analysis: } } \\ { \text {  Simplex multipliers: } y _ { B } = c _ { B } A _ { B } ^ { - 1 } \text { . } } \\ { \text { Optimal objective function value: } \bar { z } = y _ { B } b \text { . } } \\ { \text { Reduced cost: } \bar { c } _ { j } = c _ { j } - y _ { B } A _ { j } \text { . } } \\ { \text { Value of the basic variables in the BFS: } \bar { b } = A _ { B } ^ { - 1 } b \text { . } } \end{array}
$$
Basic Tableau
$$
\begin{array} { | c | c | c | c | c | c | c | c | } \hline \text { Basic } & { x _ { 1 } } & { x _ { 2 } } & { x _ { 3 } } & { x _ { 4 } } & { x _ { 5 } } & { x _ { 6 } } & { \text { Rhs } } \\ \hline ( - z ) & { 52 } & { 30 } & { 20 } & { 0 } & { 0 } & { 0 } & { 0 } \\ \hline x _ { 4 } & { 10 } & { 5 } & { 2 } & { 1 } & { 0 } & { 0 } & { 204 } \\ { x _ { 5 } } & { 2 } & { 4 } & { 5 } & { 0 } & { 1 } & { 0 } & { 100 } \\ { x _ { 6 } } & { 1 } & { 1 } & { 1 } & { 0 } & { 0 } & { 1 } & { 30 } \\ \hline \end{array}
$$
Final Tableau
$$
\begin{array} { | c | c | c | c | c | c | c | c | } \hline \text { Basic } & { x _ { 1 } } & { x _ { 2 } } & { x _ { 3 } } & { x _ { 4 } } & { x _ { 5 } } & { x _ { 6 } } & { \text { Rhs } } \\ \hline ( - z ) & { 0 } & { - 2 } & { 0 } & { - 4 } & { 0 } & { - 12 } & { - 1176 } \\ \hline x _ { 1 } & { 1 } & { 0.375 } & { 0 } & { 0.125 } & { 0 } & { - 0.25 } & { 18 } \\ { x _ { 5 } } & { 0 } & { 0.125 } & { 0 } & { 0.375 } & { 1 } & { - 5.75 } & { 4 } \\ { x _ { 3 } } & { 0 } & { 0.625 } & { 1 } & { - 0.125 } & { 0 } & { 1.25 } & { 12 } \\ \hline \end{array}
$$
$$
\begin{array} { l c } { \text { the set of basic variables: } B = \left\{ x _ { 1 } , x _ { 5 } , x _ { 3 } \right\} } \\ { \text { the basis matrix and its inverse: } } \\ { \qquad A _ { B } = \left[ \begin{array} { c c c c } { 10 } & { 0 } & { 2 } \\ { 2 } & { 1 } & { 5 } \\ { 1 } & { 0 } & { 1 } \end{array} \right] \text { and } A _ { B } ^ { - 1 } = \left[ \begin{array} { c c c } { 0.125 } & { 0 } & { - 0.25 } \\ { 0.375 } & { 1 } & { - 5.75 } \\ { - 0.125 } & { 0 } & { 1.25 } \end{array} \right] } \\ { \text { the vector of simplex multipliers: } y _ { B } = [ 4,0,12 ] } & { } \\ { \text { the reduced costs: } \bar { c } _ { N } = [ - 2 , - 4 , - 12 ] \text { and } \bar { c } _ { B } = [ 0,0,0 ] } \end{array}
$$
$$
\text { Here we have } b = ( 204,100,30 ) \text { and } \Delta b = \left( \Delta b _ { 1 } , 0,0 \right)
$$
$$
\begin{array} { c } { x _ { B } ^ { \prime } = A _ { B } ^ { - 1 } b + \Delta b _ { 1 } [ 0.125,0.375 , - 0.125 ] ^ { T } \geqslant 0 } \\ { \text { Therefore, we have a system of inequalities: } 18 + \frac { 1 } { 8 } \Delta b _ { 1 } \geqslant 0 } \\ { 4 + \frac { 3 } { 8 } \Delta b _ { 1 } \geqslant 0 , \text { and } 12 - \frac { 1 } { 8 } \Delta b _ { 1 } \geqslant 0 , \text { which yields } } \\ { - \frac { 32 } { 3 } \leqslant \Delta b _ { 1 } \leqslant 96 } \end{array}
$$
$$
\begin{array} { l } { \text { Expression for the reduced costs in tableau with basis } B : } \\ { \qquad \bar { c } _ { N } = c _ { N } - y _ { B } A _ { N } } \\ { \text { where } y _ { B } = c _ { B } A _ { B } ^ { - 1 } \text { are the shadow prices. As long as the basis } } \\ { \text { and the cost of the basic variables } c _ { B } \text { do not change, the } } \\ { \text { shadow prices will stay the same. } } \end{array}
$$
When changing non basic variables,
Since $x_2$ is nonbasic, if the basis remains optimal, change in $c_2$
affects only the reduced cost $\bar {c_2}$.
$$
\bar { c } _ { 2 } ^ { \prime } = c _ { 2 } + \Delta c _ { 2 } - y _ { B } A _ { 2 } = \Delta c _ { 2 } + \bar { c } _ { 2 } = \Delta c _ { 2 } - 2
$$
note $\bar{c_2}$ can be read of final tableau\\
For basic variables, changing it will cost change in reduced cost for all non-basic variables.\\
$$
\begin{array} { l } { \text { We require the new reduced costs to be nonpositive, i.e., } } \\ { \qquad \begin{aligned} 0 \geqslant \bar { c } _ { j } ^ { \prime } & = c _ { j } - \left( c _ { B } + \Delta c _ { 1 } e _ { 1 } \right) A _ { B } ^ { - 1 } A _ { j } \\ & = \left( c _ { j } - c _ { B } A _ { B } ^ { - 1 } A _ { j } \right) - \Delta c _ { 1 } e _ { 1 } A _ { B } ^ { - 1 } A _ { j } \\ & = \bar { c } _ { j } - \Delta c _ { 1 } e _ { 1 } A _ { B } ^ { - 1 } A _ { j } \\ & = \bar { c } _ { j } - \Delta c _ { 1 } e _ { 1 } \bar { A } _ { j } \\ & = \bar { c } _ { j } - \Delta c _ { 1 } \bar { a } _ { 1 j } \end{aligned} } \end{array}
$$
note $\bar{a_{1j}}$ can be gotten from tableau
$$
\begin{array} { l } { \text { For } j = 2,4,6 , \text { we have } } \\ { \qquad \begin{aligned} \bar { c } _ { 2 } ^ { \prime } & = - 2 - 0.375 \Delta c _ { 1 } \leqslant 0 \\ \bar { c } _ { 4 } ^ { \prime } & = - 4 - 0.125 \Delta c _ { 1 } \leqslant 0 \\ \bar { c } _ { 6 } ^ { \prime } & = - 12 - ( - 0.25 ) \Delta c _ { 1 } \leqslant 0 \end{aligned} } \\ { \text { This yields: } - \frac { 16 } { 3 } \leqslant \Delta c _ { 1 } \leqslant 48 } \end{array}
$$
(refer to tableau final above)\\
For new products (stool that require 2,1,1 processing and produce 12 in profit)
$$
\begin{array} { l } { \text { This is equivalent to adding one column to the problem: } } \\ { A _ { j } = ( 2,1,1 ) ^ { T } . \text { The corresponding reduced cost is: } } \\ { \qquad \begin{aligned} \bar { c } _ { j } = c _ { j } - y _ { B } A _ { j } , & \text { where } y _ { B } = c _ { B } A _ { B } ^ { - 1 } \\ \text { Because } y _ { B } = ( 4,0,12 ) , \text { we obtain: } \\ \bar { c } _ { j } = 12 - ( 4,0,12 ) ( 2,1,1 ) ^ { T } = 12 - 8 - 12 = - 8 \end{aligned} } \\ { \text { It is not profitable to produce stools. } } \end{array}
$$
it is not profitable to produce because the reduced cost is =8 which is not >=0,hence it will be a non basic variable in the function.\\
Notes:\\
if we change constraint RHS we just need makes sure that each of the x is value is still positive after the change, this is due to the constraint where x1,x2,x3$\geq$0,hence that's why value of x should not be negative.\\
obj function coefficient range for non basic variables is just change in cost $\leq$ |reduced cost|\\
For basic variable need do some calculation to make sure its does not change bases.\\
hence use new reduced cost of non basic variable = old reduced cost + basic variable of interest row coeff for that non basic variable * change in obj coeff\\

\section{Tutorial 7}
The shadow price is also the derivative of the optimal value function z($\Delta$).\\
Determine the binding constraints, and determine the solution to the constraints if the RHS is increased by 1. \\
Suppose that we want to modify the cost coefficient for a variable xj.  We want to increase it from cj to cj + $\Delta$.
\begin{enumerate}
  \item Determine the binding constraints and the current corner point solution, say x*.
  \item Compute the largest and smallest values of $\Delta$ so that the x* remains optimal.  In two dimensions, this will occur when the revised objective function is parallel to one of the constraints.
\end{enumerate}

\section{Tutorial 8}
Using the 100\% rule, we compute the amount of change divided by the total allowable change for each RHS that changes.  In this case, divide the proposed decrease of 10 units of warehouse space by the 28 allowable decrease and do the same for juice glasses demand.  Add up these fractions.  If the total value is less than 1, then the shadow prices are valid\\
There are a few different definitions for what reduced cost means.  It is the shadow price for the non-negativity constraint.  It is the objective value coefficient of a variable in the final and optimal tableau.  And it is the objective coefficient obtained after pricing out the constraints.\\
\section{Lecture 3\_2}
Unbounded problems have solutions where there is a positive reduced cost and non positive coefficients under that reduced cost.\\
Big M method
$$
\left.\begin{array} { r l c } { \max } & { x _ { 1 } + 3 x _ { 2 } } \\ { 2 x _ { 1 } } & { - 2 x _ { 2 } } \\ { x _ { 1 } } & { + x _ { 2 } - s _ { 1 } } \\ { x _ { 1 } , } & { x _ { 2 } , \quad s _ { 1 } , \quad s _ { 2 } , \quad s _ { 3 } \geqslant } & { 0 } \end{array} \right\}
$$
Change the objective function to $x_1 + 3x_2 - Ms_2 - Ms_3$,
where M is a very large number, and solve this new LP
using the simplex method.\\
If there are alternative optimal solutions, This is noted by having a 0 reduced cost for a non basic variable in the final tableau, we can find 2 solutions of the equation and use a technique in order to  get a line between them.
\[
\begin{pmatrix}
    x_1     \\
    x_2      \\
    x_3
\end{pmatrix}
=
\lambda
\begin{pmatrix}
    2     \\
    2\\
    0
\end{pmatrix}
+ (1-\lambda)
\begin{pmatrix}
    1      \\
    0       \\
    4
\end{pmatrix}
\]
where the 2 matrix are the 2 solutions with equal objective function value\\
Notes:\\
To find alternative optimal solution use min ratio test on column of non basic variable where cost=0\\
Use convex combination to combine the vertex of all optimal solution.\\
\section{Tutorial 9}
For max problem
\begin{enumerate}
  \item obj function coeff becomes constraint rhs values
  \item max becomes min
  \item constraint values become obj function coefficient
  \item constraint coeff transposed
  \item variables change
  \item use SOB trick to change signs
\end{enumerate}
check by using dual again, dual of dual equal primal.
sensible odd bizzare
\section{Disclaimer}
Equations may have been copied wrongly from slides, Not liable for any exams. This can only be a last minute revision and secondary source in understanding the slides and classes. Any errors is purely my fault.(Please do not blame me too badly.)
\end{document}
